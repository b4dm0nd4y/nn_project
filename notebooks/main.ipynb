{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba7015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import torchutils as tu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbe89ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_mlflow = True\n",
    "mlflow_experiment_name = 'INTEL-CNN-Experiment'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "config = {\n",
    "    'device': DEVICE,\n",
    "    'batch_size': 1024,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 5,\n",
    "    'data_dir': '../data/',\n",
    "    'log_dir': './runs/eperiment2',\n",
    "    'transformations': [\n",
    "        'resize', 'normalize'\n",
    "    ]\n",
    "}\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a374f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(256),                \n",
    "        T.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n",
    "        T.RandomRotation(15),         \n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(\n",
    "            brightness=0.1,    \n",
    "            contrast=0.1,      \n",
    "        ),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "valid_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9b1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    config['data_dir']+ 'seg_train/seg_train',\n",
    "    transform=train_transforms\n",
    "    )\n",
    "\n",
    "valid_dataset = datasets.ImageFolder(\n",
    "    config['data_dir']+ 'seg_test/seg_test',\n",
    "    transform=train_transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d7da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32274b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sea'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\n",
    "    0: 'buildings',\n",
    "    1: 'forest',\n",
    "    2: 'glacier',\n",
    "    3: 'mountain',\n",
    "    4: 'sea',\n",
    "    5: 'street'\n",
    "}\n",
    "\n",
    "decode = lambda x: labels[x]\n",
    "decode(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a164c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba52c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "       \n",
    "model.fc = nn.Linear(2048, 6)\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e24cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), config['learning_rate'])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78cbc281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================================\n",
      "Layer                                         Kernel                Output           Params               FLOPs\n",
      "===============================================================================================================\n",
      "0_conv1                                      [3, 64, 7, 7]   [1024, 64, 112, 112]       9,408   120,846,286,848\n",
      "1_bn1                                                 [64]   [1024, 64, 112, 112]         128     3,288,334,336\n",
      "2_relu                                                   -   [1024, 64, 112, 112]           0                 0\n",
      "3_maxpool                                                -     [1024, 64, 56, 56]           0                 0\n",
      "4_layer1.0.Conv2d_conv1                     [64, 64, 1, 1]     [1024, 64, 56, 56]       4,096    13,153,337,344\n",
      "5_layer1.0.BatchNorm2d_bn1                            [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "6_layer1.0.ReLU_relu                                     -     [1024, 64, 56, 56]           0                 0\n",
      "7_layer1.0.Conv2d_conv2                     [64, 64, 3, 3]     [1024, 64, 56, 56]      36,864   118,380,036,096\n",
      "8_layer1.0.BatchNorm2d_bn2                            [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "9_layer1.0.ReLU_relu                                     -     [1024, 64, 56, 56]           0                 0\n",
      "10_layer1.0.Conv2d_conv3                   [64, 256, 1, 1]    [1024, 256, 56, 56]      16,384    52,613,349,376\n",
      "11_layer1.0.BatchNorm2d_bn3                          [256]    [1024, 256, 56, 56]         512     3,288,334,336\n",
      "12_layer1.0.downsample.Conv2d_0            [64, 256, 1, 1]    [1024, 256, 56, 56]      16,384    52,613,349,376\n",
      "13_layer1.0.downsample.BatchNorm2d_1                 [256]    [1024, 256, 56, 56]         512     3,288,334,336\n",
      "14_layer1.0.ReLU_relu                                    -    [1024, 256, 56, 56]           0                 0\n",
      "15_layer1.1.Conv2d_conv1                   [256, 64, 1, 1]     [1024, 64, 56, 56]      16,384    52,613,349,376\n",
      "16_layer1.1.BatchNorm2d_bn1                           [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "17_layer1.1.ReLU_relu                                    -     [1024, 64, 56, 56]           0                 0\n",
      "18_layer1.1.Conv2d_conv2                    [64, 64, 3, 3]     [1024, 64, 56, 56]      36,864   118,380,036,096\n",
      "19_layer1.1.BatchNorm2d_bn2                           [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "20_layer1.1.ReLU_relu                                    -     [1024, 64, 56, 56]           0                 0\n",
      "21_layer1.1.Conv2d_conv3                   [64, 256, 1, 1]    [1024, 256, 56, 56]      16,384    52,613,349,376\n",
      "22_layer1.1.BatchNorm2d_bn3                          [256]    [1024, 256, 56, 56]         512     3,288,334,336\n",
      "23_layer1.1.ReLU_relu                                    -    [1024, 256, 56, 56]           0                 0\n",
      "24_layer1.2.Conv2d_conv1                   [256, 64, 1, 1]     [1024, 64, 56, 56]      16,384    52,613,349,376\n",
      "25_layer1.2.BatchNorm2d_bn1                           [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "26_layer1.2.ReLU_relu                                    -     [1024, 64, 56, 56]           0                 0\n",
      "27_layer1.2.Conv2d_conv2                    [64, 64, 3, 3]     [1024, 64, 56, 56]      36,864   118,380,036,096\n",
      "28_layer1.2.BatchNorm2d_bn2                           [64]     [1024, 64, 56, 56]         128       822,083,584\n",
      "29_layer1.2.ReLU_relu                                    -     [1024, 64, 56, 56]           0                 0\n",
      "30_layer1.2.Conv2d_conv3                   [64, 256, 1, 1]    [1024, 256, 56, 56]      16,384    52,613,349,376\n",
      "31_layer1.2.BatchNorm2d_bn3                          [256]    [1024, 256, 56, 56]         512     3,288,334,336\n",
      "32_layer1.2.ReLU_relu                                    -    [1024, 256, 56, 56]           0                 0\n",
      "33_layer2.0.Conv2d_conv1                  [256, 128, 1, 1]    [1024, 128, 56, 56]      32,768   105,226,698,752\n",
      "34_layer2.0.BatchNorm2d_bn1                          [128]    [1024, 128, 56, 56]         256     1,644,167,168\n",
      "35_layer2.0.ReLU_relu                                    -    [1024, 128, 56, 56]           0                 0\n",
      "36_layer2.0.Conv2d_conv2                  [128, 128, 3, 3]    [1024, 128, 28, 28]     147,456   118,380,036,096\n",
      "37_layer2.0.BatchNorm2d_bn2                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "38_layer2.0.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "39_layer2.0.Conv2d_conv3                  [128, 512, 1, 1]    [1024, 512, 28, 28]      65,536    52,613,349,376\n",
      "40_layer2.0.BatchNorm2d_bn3                          [512]    [1024, 512, 28, 28]       1,024     1,644,167,168\n",
      "41_layer2.0.downsample.Conv2d_0           [256, 512, 1, 1]    [1024, 512, 28, 28]     131,072   105,226,698,752\n",
      "42_layer2.0.downsample.BatchNorm2d_1                 [512]    [1024, 512, 28, 28]       1,024     1,644,167,168\n",
      "43_layer2.0.ReLU_relu                                    -    [1024, 512, 28, 28]           0                 0\n",
      "44_layer2.1.Conv2d_conv1                  [512, 128, 1, 1]    [1024, 128, 28, 28]      65,536    52,613,349,376\n",
      "45_layer2.1.BatchNorm2d_bn1                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "46_layer2.1.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "47_layer2.1.Conv2d_conv2                  [128, 128, 3, 3]    [1024, 128, 28, 28]     147,456   118,380,036,096\n",
      "48_layer2.1.BatchNorm2d_bn2                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "49_layer2.1.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "50_layer2.1.Conv2d_conv3                  [128, 512, 1, 1]    [1024, 512, 28, 28]      65,536    52,613,349,376\n",
      "51_layer2.1.BatchNorm2d_bn3                          [512]    [1024, 512, 28, 28]       1,024     1,644,167,168\n",
      "52_layer2.1.ReLU_relu                                    -    [1024, 512, 28, 28]           0                 0\n",
      "53_layer2.2.Conv2d_conv1                  [512, 128, 1, 1]    [1024, 128, 28, 28]      65,536    52,613,349,376\n",
      "54_layer2.2.BatchNorm2d_bn1                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "55_layer2.2.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "56_layer2.2.Conv2d_conv2                  [128, 128, 3, 3]    [1024, 128, 28, 28]     147,456   118,380,036,096\n",
      "57_layer2.2.BatchNorm2d_bn2                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "58_layer2.2.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "59_layer2.2.Conv2d_conv3                  [128, 512, 1, 1]    [1024, 512, 28, 28]      65,536    52,613,349,376\n",
      "60_layer2.2.BatchNorm2d_bn3                          [512]    [1024, 512, 28, 28]       1,024     1,644,167,168\n",
      "61_layer2.2.ReLU_relu                                    -    [1024, 512, 28, 28]           0                 0\n",
      "62_layer2.3.Conv2d_conv1                  [512, 128, 1, 1]    [1024, 128, 28, 28]      65,536    52,613,349,376\n",
      "63_layer2.3.BatchNorm2d_bn1                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "64_layer2.3.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "65_layer2.3.Conv2d_conv2                  [128, 128, 3, 3]    [1024, 128, 28, 28]     147,456   118,380,036,096\n",
      "66_layer2.3.BatchNorm2d_bn2                          [128]    [1024, 128, 28, 28]         256       411,041,792\n",
      "67_layer2.3.ReLU_relu                                    -    [1024, 128, 28, 28]           0                 0\n",
      "68_layer2.3.Conv2d_conv3                  [128, 512, 1, 1]    [1024, 512, 28, 28]      65,536    52,613,349,376\n",
      "69_layer2.3.BatchNorm2d_bn3                          [512]    [1024, 512, 28, 28]       1,024     1,644,167,168\n",
      "70_layer2.3.ReLU_relu                                    -    [1024, 512, 28, 28]           0                 0\n",
      "71_layer3.0.Conv2d_conv1                  [512, 256, 1, 1]    [1024, 256, 28, 28]     131,072   105,226,698,752\n",
      "72_layer3.0.BatchNorm2d_bn1                          [256]    [1024, 256, 28, 28]         512       822,083,584\n",
      "73_layer3.0.ReLU_relu                                    -    [1024, 256, 28, 28]           0                 0\n",
      "74_layer3.0.Conv2d_conv2                  [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "75_layer3.0.BatchNorm2d_bn2                          [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "76_layer3.0.ReLU_relu                                    -    [1024, 256, 14, 14]           0                 0\n",
      "77_layer3.0.Conv2d_conv3                 [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "78_layer3.0.BatchNorm2d_bn3                         [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "79_layer3.0.downsample.Conv2d_0          [512, 1024, 1, 1]   [1024, 1024, 14, 14]     524,288   105,226,698,752\n",
      "80_layer3.0.downsample.BatchNorm2d_1                [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "81_layer3.0.ReLU_relu                                    -   [1024, 1024, 14, 14]           0                 0\n",
      "82_layer3.1.Conv2d_conv1                 [1024, 256, 1, 1]    [1024, 256, 14, 14]     262,144    52,613,349,376\n",
      "83_layer3.1.BatchNorm2d_bn1                          [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "84_layer3.1.ReLU_relu                                    -    [1024, 256, 14, 14]           0                 0\n",
      "85_layer3.1.Conv2d_conv2                  [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "86_layer3.1.BatchNorm2d_bn2                          [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "87_layer3.1.ReLU_relu                                    -    [1024, 256, 14, 14]           0                 0\n",
      "88_layer3.1.Conv2d_conv3                 [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "89_layer3.1.BatchNorm2d_bn3                         [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "90_layer3.1.ReLU_relu                                    -   [1024, 1024, 14, 14]           0                 0\n",
      "91_layer3.2.Conv2d_conv1                 [1024, 256, 1, 1]    [1024, 256, 14, 14]     262,144    52,613,349,376\n",
      "92_layer3.2.BatchNorm2d_bn1                          [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "93_layer3.2.ReLU_relu                                    -    [1024, 256, 14, 14]           0                 0\n",
      "94_layer3.2.Conv2d_conv2                  [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "95_layer3.2.BatchNorm2d_bn2                          [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "96_layer3.2.ReLU_relu                                    -    [1024, 256, 14, 14]           0                 0\n",
      "97_layer3.2.Conv2d_conv3                 [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "98_layer3.2.BatchNorm2d_bn3                         [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "99_layer3.2.ReLU_relu                                    -   [1024, 1024, 14, 14]           0                 0\n",
      "100_layer3.3.Conv2d_conv1                [1024, 256, 1, 1]    [1024, 256, 14, 14]     262,144    52,613,349,376\n",
      "101_layer3.3.BatchNorm2d_bn1                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "102_layer3.3.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "103_layer3.3.Conv2d_conv2                 [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "104_layer3.3.BatchNorm2d_bn2                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "105_layer3.3.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "106_layer3.3.Conv2d_conv3                [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "107_layer3.3.BatchNorm2d_bn3                        [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "108_layer3.3.ReLU_relu                                   -   [1024, 1024, 14, 14]           0                 0\n",
      "109_layer3.4.Conv2d_conv1                [1024, 256, 1, 1]    [1024, 256, 14, 14]     262,144    52,613,349,376\n",
      "110_layer3.4.BatchNorm2d_bn1                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "111_layer3.4.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "112_layer3.4.Conv2d_conv2                 [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "113_layer3.4.BatchNorm2d_bn2                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "114_layer3.4.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "115_layer3.4.Conv2d_conv3                [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "116_layer3.4.BatchNorm2d_bn3                        [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "117_layer3.4.ReLU_relu                                   -   [1024, 1024, 14, 14]           0                 0\n",
      "118_layer3.5.Conv2d_conv1                [1024, 256, 1, 1]    [1024, 256, 14, 14]     262,144    52,613,349,376\n",
      "119_layer3.5.BatchNorm2d_bn1                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "120_layer3.5.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "121_layer3.5.Conv2d_conv2                 [256, 256, 3, 3]    [1024, 256, 14, 14]     589,824   118,380,036,096\n",
      "122_layer3.5.BatchNorm2d_bn2                         [256]    [1024, 256, 14, 14]         512       205,520,896\n",
      "123_layer3.5.ReLU_relu                                   -    [1024, 256, 14, 14]           0                 0\n",
      "124_layer3.5.Conv2d_conv3                [256, 1024, 1, 1]   [1024, 1024, 14, 14]     262,144    52,613,349,376\n",
      "125_layer3.5.BatchNorm2d_bn3                        [1024]   [1024, 1024, 14, 14]       2,048       822,083,584\n",
      "126_layer3.5.ReLU_relu                                   -   [1024, 1024, 14, 14]           0                 0\n",
      "127_layer4.0.Conv2d_conv1                [1024, 512, 1, 1]    [1024, 512, 14, 14]     524,288   105,226,698,752\n",
      "128_layer4.0.BatchNorm2d_bn1                         [512]    [1024, 512, 14, 14]       1,024       411,041,792\n",
      "129_layer4.0.ReLU_relu                                   -    [1024, 512, 14, 14]           0                 0\n",
      "130_layer4.0.Conv2d_conv2                 [512, 512, 3, 3]      [1024, 512, 7, 7]   2,359,296   118,380,036,096\n",
      "131_layer4.0.BatchNorm2d_bn2                         [512]      [1024, 512, 7, 7]       1,024       102,760,448\n",
      "132_layer4.0.ReLU_relu                                   -      [1024, 512, 7, 7]           0                 0\n",
      "133_layer4.0.Conv2d_conv3                [512, 2048, 1, 1]     [1024, 2048, 7, 7]   1,048,576    52,613,349,376\n",
      "134_layer4.0.BatchNorm2d_bn3                        [2048]     [1024, 2048, 7, 7]       4,096       411,041,792\n",
      "135_layer4.0.downsample.Conv2d_0        [1024, 2048, 1, 1]     [1024, 2048, 7, 7]   2,097,152   105,226,698,752\n",
      "136_layer4.0.downsample.BatchNorm2d_1               [2048]     [1024, 2048, 7, 7]       4,096       411,041,792\n",
      "137_layer4.0.ReLU_relu                                   -     [1024, 2048, 7, 7]           0                 0\n",
      "138_layer4.1.Conv2d_conv1                [2048, 512, 1, 1]      [1024, 512, 7, 7]   1,048,576    52,613,349,376\n",
      "139_layer4.1.BatchNorm2d_bn1                         [512]      [1024, 512, 7, 7]       1,024       102,760,448\n",
      "140_layer4.1.ReLU_relu                                   -      [1024, 512, 7, 7]           0                 0\n",
      "141_layer4.1.Conv2d_conv2                 [512, 512, 3, 3]      [1024, 512, 7, 7]   2,359,296   118,380,036,096\n",
      "142_layer4.1.BatchNorm2d_bn2                         [512]      [1024, 512, 7, 7]       1,024       102,760,448\n",
      "143_layer4.1.ReLU_relu                                   -      [1024, 512, 7, 7]           0                 0\n",
      "144_layer4.1.Conv2d_conv3                [512, 2048, 1, 1]     [1024, 2048, 7, 7]   1,048,576    52,613,349,376\n",
      "145_layer4.1.BatchNorm2d_bn3                        [2048]     [1024, 2048, 7, 7]       4,096       411,041,792\n",
      "146_layer4.1.ReLU_relu                                   -     [1024, 2048, 7, 7]           0                 0\n",
      "147_layer4.2.Conv2d_conv1                [2048, 512, 1, 1]      [1024, 512, 7, 7]   1,048,576    52,613,349,376\n",
      "148_layer4.2.BatchNorm2d_bn1                         [512]      [1024, 512, 7, 7]       1,024       102,760,448\n",
      "149_layer4.2.ReLU_relu                                   -      [1024, 512, 7, 7]           0                 0\n",
      "150_layer4.2.Conv2d_conv2                 [512, 512, 3, 3]      [1024, 512, 7, 7]   2,359,296   118,380,036,096\n",
      "151_layer4.2.BatchNorm2d_bn2                         [512]      [1024, 512, 7, 7]       1,024       102,760,448\n",
      "152_layer4.2.ReLU_relu                                   -      [1024, 512, 7, 7]           0                 0\n",
      "153_layer4.2.Conv2d_conv3                [512, 2048, 1, 1]     [1024, 2048, 7, 7]   1,048,576    52,613,349,376\n",
      "154_layer4.2.BatchNorm2d_bn3                        [2048]     [1024, 2048, 7, 7]       4,096       411,041,792\n",
      "155_layer4.2.ReLU_relu                                   -     [1024, 2048, 7, 7]           0                 0\n",
      "156_avgpool                                              -     [1024, 2048, 1, 1]           0       104,857,600\n",
      "157_fc                                           [2048, 6]              [1024, 6]      12,294        25,159,680\n",
      "===============================================================================================================\n",
      "Total params: 23,520,326\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,508,032\n",
      "Total FLOPs: 4,230,880,421,888 / 4230.88 GFLOPs\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 588.00\n",
      "Forward/backward pass size (MB): 250308.05\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 250985.77\n",
      "===============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "tu.get_model_summary(model, torch.randn(config['batch_size'], 3, 224, 224, device=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb209bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] Train loss: 1.3556, valid loss = 0.9476 Train acc 0.6450 Valid acc 0.8221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m batch_acc = []\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:247\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    245\u001b[39m sample = \u001b[38;5;28mself\u001b[39m.loader(path)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    249\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:973\u001b[39m, in \u001b[36mRandomResizedCrop.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    966\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    967\u001b[39m \u001b[33;03m    img (PIL Image or Tensor): Image to be cropped and resized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m \u001b[33;03m    PIL Image or Tensor: Randomly cropped and resized image.\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    972\u001b[39m i, j, h, w = \u001b[38;5;28mself\u001b[39m.get_params(img, \u001b[38;5;28mself\u001b[39m.scale, \u001b[38;5;28mself\u001b[39m.ratio)\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresized_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:650\u001b[39m, in \u001b[36mresized_crop\u001b[39m\u001b[34m(img, top, left, height, width, size, interpolation, antialias)\u001b[39m\n\u001b[32m    648\u001b[39m     _log_api_usage_once(resized_crop)\n\u001b[32m    649\u001b[39m img = crop(img, top, left, height, width)\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m img = \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:477\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    475\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m     pil_interpolation = pil_modes_mapping[interpolation]\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F_t.resize(img, size=output_size, interpolation=interpolation.value, antialias=antialias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) == \u001b[32m2\u001b[39m):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bootcamp/nn_project/.venv/lib/python3.12/site-packages/PIL/Image.py:2316\u001b[39m, in \u001b[36mImage.resize\u001b[39m\u001b[34m(self, size, resample, box, reducing_gap)\u001b[39m\n\u001b[32m   2304\u001b[39m         \u001b[38;5;28mself\u001b[39m = (\n\u001b[32m   2305\u001b[39m             \u001b[38;5;28mself\u001b[39m.reduce(factor, box=reduce_box)\n\u001b[32m   2306\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.reduce)\n\u001b[32m   2307\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Image.reduce(\u001b[38;5;28mself\u001b[39m, factor, box=reduce_box)\n\u001b[32m   2308\u001b[39m         )\n\u001b[32m   2309\u001b[39m         box = (\n\u001b[32m   2310\u001b[39m             (box[\u001b[32m0\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2311\u001b[39m             (box[\u001b[32m1\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2312\u001b[39m             (box[\u001b[32m2\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2313\u001b[39m             (box[\u001b[32m3\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2314\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_epoch_acc = []\n",
    "train_epoch_losses = []\n",
    "valid_epoch_losses = []\n",
    "valid_epoch_acc = []\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc = (preds == labels).sum().item() / labels.size(0)\n",
    "        batch_acc.append(acc)\n",
    "        \n",
    "    train_epoch_acc.append(np.mean(batch_acc))\n",
    "    train_epoch_losses.append(np.mean(batch_loss))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = (preds == labels).sum().item() / labels.size(0)\n",
    "            batch_acc.append(acc)\n",
    "            \n",
    "    valid_epoch_losses.append(np.mean(batch_loss))\n",
    "    valid_epoch_acc.append(np.mean(batch_acc))\n",
    "    print(f'[Epoch {epoch:02d}] Train loss: {train_epoch_losses[-1]:.4f}, valid loss = {valid_epoch_losses[-1]:.4f} Train acc {train_epoch_acc[-1]:.4f} Valid acc {valid_epoch_acc[-1]:.4f}')\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "ax[0].plot(train_epoch_losses)\n",
    "ax[0].plot(valid_epoch_losses)\n",
    "ax[0].set_ylim((0, np.max(train_epoch_losses.extend(valid_epoch_losses))))\n",
    "ax[0].set_title('Valid loss history')\n",
    "\n",
    "ax[1].plot(train_epoch_acc)\n",
    "ax[1].plot(valid_epoch_acc)\n",
    "ax[1].set_ylim(0, 1.1)\n",
    "ax[1].set_title('Acc history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102feb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

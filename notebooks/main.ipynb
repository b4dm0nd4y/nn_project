{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba7015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import torchutils as tu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbe89ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_mlflow = True\n",
    "mlflow_experiment_name = 'INTEL-CNN-Experiment'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "config = {\n",
    "    'device': DEVICE,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 5,\n",
    "    'data_dir': '../data/',\n",
    "    'log_dir': './runs/eperiment2',\n",
    "    'transformations': [\n",
    "        'resize', 'normalize'\n",
    "    ]\n",
    "}\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a374f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(256),                \n",
    "        T.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n",
    "        T.RandomRotation(15),         \n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(\n",
    "            brightness=0.1,    \n",
    "            contrast=0.1,      \n",
    "        ),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "valid_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9b1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    config['data_dir']+ 'seg_train/seg_train',\n",
    "    transform=train_transforms\n",
    "    )\n",
    "\n",
    "valid_dataset = datasets.ImageFolder(\n",
    "    config['data_dir']+ 'seg_test/seg_test',\n",
    "    transform=train_transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d7da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32274b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sea'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\n",
    "    0: 'buildings',\n",
    "    1: 'forest',\n",
    "    2: 'glacier',\n",
    "    3: 'mountain',\n",
    "    4: 'sea',\n",
    "    5: 'street'\n",
    "}\n",
    "\n",
    "decode = lambda x: labels[x]\n",
    "decode(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a164c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba52c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "       \n",
    "model.fc = nn.Linear(2048, 6)\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e24cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78cbc281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================================\n",
      "Layer                                         Kernel               Output           Params              FLOPs\n",
      "=============================================================================================================\n",
      "0_conv1                                      [3, 64, 7, 7]   [128, 64, 112, 112]       9,408   15,105,785,856\n",
      "1_bn1                                                 [64]   [128, 64, 112, 112]         128      411,041,792\n",
      "2_relu                                                   -   [128, 64, 112, 112]           0                0\n",
      "3_maxpool                                                -     [128, 64, 56, 56]           0                0\n",
      "4_layer1.0.Conv2d_conv1                     [64, 64, 1, 1]     [128, 64, 56, 56]       4,096    1,644,167,168\n",
      "5_layer1.0.BatchNorm2d_bn1                            [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "6_layer1.0.ReLU_relu                                     -     [128, 64, 56, 56]           0                0\n",
      "7_layer1.0.Conv2d_conv2                     [64, 64, 3, 3]     [128, 64, 56, 56]      36,864   14,797,504,512\n",
      "8_layer1.0.BatchNorm2d_bn2                            [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "9_layer1.0.ReLU_relu                                     -     [128, 64, 56, 56]           0                0\n",
      "10_layer1.0.Conv2d_conv3                   [64, 256, 1, 1]    [128, 256, 56, 56]      16,384    6,576,668,672\n",
      "11_layer1.0.BatchNorm2d_bn3                          [256]    [128, 256, 56, 56]         512      411,041,792\n",
      "12_layer1.0.downsample.Conv2d_0            [64, 256, 1, 1]    [128, 256, 56, 56]      16,384    6,576,668,672\n",
      "13_layer1.0.downsample.BatchNorm2d_1                 [256]    [128, 256, 56, 56]         512      411,041,792\n",
      "14_layer1.0.ReLU_relu                                    -    [128, 256, 56, 56]           0                0\n",
      "15_layer1.1.Conv2d_conv1                   [256, 64, 1, 1]     [128, 64, 56, 56]      16,384    6,576,668,672\n",
      "16_layer1.1.BatchNorm2d_bn1                           [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "17_layer1.1.ReLU_relu                                    -     [128, 64, 56, 56]           0                0\n",
      "18_layer1.1.Conv2d_conv2                    [64, 64, 3, 3]     [128, 64, 56, 56]      36,864   14,797,504,512\n",
      "19_layer1.1.BatchNorm2d_bn2                           [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "20_layer1.1.ReLU_relu                                    -     [128, 64, 56, 56]           0                0\n",
      "21_layer1.1.Conv2d_conv3                   [64, 256, 1, 1]    [128, 256, 56, 56]      16,384    6,576,668,672\n",
      "22_layer1.1.BatchNorm2d_bn3                          [256]    [128, 256, 56, 56]         512      411,041,792\n",
      "23_layer1.1.ReLU_relu                                    -    [128, 256, 56, 56]           0                0\n",
      "24_layer1.2.Conv2d_conv1                   [256, 64, 1, 1]     [128, 64, 56, 56]      16,384    6,576,668,672\n",
      "25_layer1.2.BatchNorm2d_bn1                           [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "26_layer1.2.ReLU_relu                                    -     [128, 64, 56, 56]           0                0\n",
      "27_layer1.2.Conv2d_conv2                    [64, 64, 3, 3]     [128, 64, 56, 56]      36,864   14,797,504,512\n",
      "28_layer1.2.BatchNorm2d_bn2                           [64]     [128, 64, 56, 56]         128      102,760,448\n",
      "29_layer1.2.ReLU_relu                                    -     [128, 64, 56, 56]           0                0\n",
      "30_layer1.2.Conv2d_conv3                   [64, 256, 1, 1]    [128, 256, 56, 56]      16,384    6,576,668,672\n",
      "31_layer1.2.BatchNorm2d_bn3                          [256]    [128, 256, 56, 56]         512      411,041,792\n",
      "32_layer1.2.ReLU_relu                                    -    [128, 256, 56, 56]           0                0\n",
      "33_layer2.0.Conv2d_conv1                  [256, 128, 1, 1]    [128, 128, 56, 56]      32,768   13,153,337,344\n",
      "34_layer2.0.BatchNorm2d_bn1                          [128]    [128, 128, 56, 56]         256      205,520,896\n",
      "35_layer2.0.ReLU_relu                                    -    [128, 128, 56, 56]           0                0\n",
      "36_layer2.0.Conv2d_conv2                  [128, 128, 3, 3]    [128, 128, 28, 28]     147,456   14,797,504,512\n",
      "37_layer2.0.BatchNorm2d_bn2                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "38_layer2.0.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "39_layer2.0.Conv2d_conv3                  [128, 512, 1, 1]    [128, 512, 28, 28]      65,536    6,576,668,672\n",
      "40_layer2.0.BatchNorm2d_bn3                          [512]    [128, 512, 28, 28]       1,024      205,520,896\n",
      "41_layer2.0.downsample.Conv2d_0           [256, 512, 1, 1]    [128, 512, 28, 28]     131,072   13,153,337,344\n",
      "42_layer2.0.downsample.BatchNorm2d_1                 [512]    [128, 512, 28, 28]       1,024      205,520,896\n",
      "43_layer2.0.ReLU_relu                                    -    [128, 512, 28, 28]           0                0\n",
      "44_layer2.1.Conv2d_conv1                  [512, 128, 1, 1]    [128, 128, 28, 28]      65,536    6,576,668,672\n",
      "45_layer2.1.BatchNorm2d_bn1                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "46_layer2.1.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "47_layer2.1.Conv2d_conv2                  [128, 128, 3, 3]    [128, 128, 28, 28]     147,456   14,797,504,512\n",
      "48_layer2.1.BatchNorm2d_bn2                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "49_layer2.1.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "50_layer2.1.Conv2d_conv3                  [128, 512, 1, 1]    [128, 512, 28, 28]      65,536    6,576,668,672\n",
      "51_layer2.1.BatchNorm2d_bn3                          [512]    [128, 512, 28, 28]       1,024      205,520,896\n",
      "52_layer2.1.ReLU_relu                                    -    [128, 512, 28, 28]           0                0\n",
      "53_layer2.2.Conv2d_conv1                  [512, 128, 1, 1]    [128, 128, 28, 28]      65,536    6,576,668,672\n",
      "54_layer2.2.BatchNorm2d_bn1                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "55_layer2.2.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "56_layer2.2.Conv2d_conv2                  [128, 128, 3, 3]    [128, 128, 28, 28]     147,456   14,797,504,512\n",
      "57_layer2.2.BatchNorm2d_bn2                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "58_layer2.2.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "59_layer2.2.Conv2d_conv3                  [128, 512, 1, 1]    [128, 512, 28, 28]      65,536    6,576,668,672\n",
      "60_layer2.2.BatchNorm2d_bn3                          [512]    [128, 512, 28, 28]       1,024      205,520,896\n",
      "61_layer2.2.ReLU_relu                                    -    [128, 512, 28, 28]           0                0\n",
      "62_layer2.3.Conv2d_conv1                  [512, 128, 1, 1]    [128, 128, 28, 28]      65,536    6,576,668,672\n",
      "63_layer2.3.BatchNorm2d_bn1                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "64_layer2.3.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "65_layer2.3.Conv2d_conv2                  [128, 128, 3, 3]    [128, 128, 28, 28]     147,456   14,797,504,512\n",
      "66_layer2.3.BatchNorm2d_bn2                          [128]    [128, 128, 28, 28]         256       51,380,224\n",
      "67_layer2.3.ReLU_relu                                    -    [128, 128, 28, 28]           0                0\n",
      "68_layer2.3.Conv2d_conv3                  [128, 512, 1, 1]    [128, 512, 28, 28]      65,536    6,576,668,672\n",
      "69_layer2.3.BatchNorm2d_bn3                          [512]    [128, 512, 28, 28]       1,024      205,520,896\n",
      "70_layer2.3.ReLU_relu                                    -    [128, 512, 28, 28]           0                0\n",
      "71_layer3.0.Conv2d_conv1                  [512, 256, 1, 1]    [128, 256, 28, 28]     131,072   13,153,337,344\n",
      "72_layer3.0.BatchNorm2d_bn1                          [256]    [128, 256, 28, 28]         512      102,760,448\n",
      "73_layer3.0.ReLU_relu                                    -    [128, 256, 28, 28]           0                0\n",
      "74_layer3.0.Conv2d_conv2                  [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "75_layer3.0.BatchNorm2d_bn2                          [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "76_layer3.0.ReLU_relu                                    -    [128, 256, 14, 14]           0                0\n",
      "77_layer3.0.Conv2d_conv3                 [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "78_layer3.0.BatchNorm2d_bn3                         [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "79_layer3.0.downsample.Conv2d_0          [512, 1024, 1, 1]   [128, 1024, 14, 14]     524,288   13,153,337,344\n",
      "80_layer3.0.downsample.BatchNorm2d_1                [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "81_layer3.0.ReLU_relu                                    -   [128, 1024, 14, 14]           0                0\n",
      "82_layer3.1.Conv2d_conv1                 [1024, 256, 1, 1]    [128, 256, 14, 14]     262,144    6,576,668,672\n",
      "83_layer3.1.BatchNorm2d_bn1                          [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "84_layer3.1.ReLU_relu                                    -    [128, 256, 14, 14]           0                0\n",
      "85_layer3.1.Conv2d_conv2                  [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "86_layer3.1.BatchNorm2d_bn2                          [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "87_layer3.1.ReLU_relu                                    -    [128, 256, 14, 14]           0                0\n",
      "88_layer3.1.Conv2d_conv3                 [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "89_layer3.1.BatchNorm2d_bn3                         [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "90_layer3.1.ReLU_relu                                    -   [128, 1024, 14, 14]           0                0\n",
      "91_layer3.2.Conv2d_conv1                 [1024, 256, 1, 1]    [128, 256, 14, 14]     262,144    6,576,668,672\n",
      "92_layer3.2.BatchNorm2d_bn1                          [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "93_layer3.2.ReLU_relu                                    -    [128, 256, 14, 14]           0                0\n",
      "94_layer3.2.Conv2d_conv2                  [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "95_layer3.2.BatchNorm2d_bn2                          [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "96_layer3.2.ReLU_relu                                    -    [128, 256, 14, 14]           0                0\n",
      "97_layer3.2.Conv2d_conv3                 [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "98_layer3.2.BatchNorm2d_bn3                         [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "99_layer3.2.ReLU_relu                                    -   [128, 1024, 14, 14]           0                0\n",
      "100_layer3.3.Conv2d_conv1                [1024, 256, 1, 1]    [128, 256, 14, 14]     262,144    6,576,668,672\n",
      "101_layer3.3.BatchNorm2d_bn1                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "102_layer3.3.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "103_layer3.3.Conv2d_conv2                 [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "104_layer3.3.BatchNorm2d_bn2                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "105_layer3.3.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "106_layer3.3.Conv2d_conv3                [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "107_layer3.3.BatchNorm2d_bn3                        [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "108_layer3.3.ReLU_relu                                   -   [128, 1024, 14, 14]           0                0\n",
      "109_layer3.4.Conv2d_conv1                [1024, 256, 1, 1]    [128, 256, 14, 14]     262,144    6,576,668,672\n",
      "110_layer3.4.BatchNorm2d_bn1                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "111_layer3.4.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "112_layer3.4.Conv2d_conv2                 [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "113_layer3.4.BatchNorm2d_bn2                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "114_layer3.4.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "115_layer3.4.Conv2d_conv3                [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "116_layer3.4.BatchNorm2d_bn3                        [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "117_layer3.4.ReLU_relu                                   -   [128, 1024, 14, 14]           0                0\n",
      "118_layer3.5.Conv2d_conv1                [1024, 256, 1, 1]    [128, 256, 14, 14]     262,144    6,576,668,672\n",
      "119_layer3.5.BatchNorm2d_bn1                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "120_layer3.5.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "121_layer3.5.Conv2d_conv2                 [256, 256, 3, 3]    [128, 256, 14, 14]     589,824   14,797,504,512\n",
      "122_layer3.5.BatchNorm2d_bn2                         [256]    [128, 256, 14, 14]         512       25,690,112\n",
      "123_layer3.5.ReLU_relu                                   -    [128, 256, 14, 14]           0                0\n",
      "124_layer3.5.Conv2d_conv3                [256, 1024, 1, 1]   [128, 1024, 14, 14]     262,144    6,576,668,672\n",
      "125_layer3.5.BatchNorm2d_bn3                        [1024]   [128, 1024, 14, 14]       2,048      102,760,448\n",
      "126_layer3.5.ReLU_relu                                   -   [128, 1024, 14, 14]           0                0\n",
      "127_layer4.0.Conv2d_conv1                [1024, 512, 1, 1]    [128, 512, 14, 14]     524,288   13,153,337,344\n",
      "128_layer4.0.BatchNorm2d_bn1                         [512]    [128, 512, 14, 14]       1,024       51,380,224\n",
      "129_layer4.0.ReLU_relu                                   -    [128, 512, 14, 14]           0                0\n",
      "130_layer4.0.Conv2d_conv2                 [512, 512, 3, 3]      [128, 512, 7, 7]   2,359,296   14,797,504,512\n",
      "131_layer4.0.BatchNorm2d_bn2                         [512]      [128, 512, 7, 7]       1,024       12,845,056\n",
      "132_layer4.0.ReLU_relu                                   -      [128, 512, 7, 7]           0                0\n",
      "133_layer4.0.Conv2d_conv3                [512, 2048, 1, 1]     [128, 2048, 7, 7]   1,048,576    6,576,668,672\n",
      "134_layer4.0.BatchNorm2d_bn3                        [2048]     [128, 2048, 7, 7]       4,096       51,380,224\n",
      "135_layer4.0.downsample.Conv2d_0        [1024, 2048, 1, 1]     [128, 2048, 7, 7]   2,097,152   13,153,337,344\n",
      "136_layer4.0.downsample.BatchNorm2d_1               [2048]     [128, 2048, 7, 7]       4,096       51,380,224\n",
      "137_layer4.0.ReLU_relu                                   -     [128, 2048, 7, 7]           0                0\n",
      "138_layer4.1.Conv2d_conv1                [2048, 512, 1, 1]      [128, 512, 7, 7]   1,048,576    6,576,668,672\n",
      "139_layer4.1.BatchNorm2d_bn1                         [512]      [128, 512, 7, 7]       1,024       12,845,056\n",
      "140_layer4.1.ReLU_relu                                   -      [128, 512, 7, 7]           0                0\n",
      "141_layer4.1.Conv2d_conv2                 [512, 512, 3, 3]      [128, 512, 7, 7]   2,359,296   14,797,504,512\n",
      "142_layer4.1.BatchNorm2d_bn2                         [512]      [128, 512, 7, 7]       1,024       12,845,056\n",
      "143_layer4.1.ReLU_relu                                   -      [128, 512, 7, 7]           0                0\n",
      "144_layer4.1.Conv2d_conv3                [512, 2048, 1, 1]     [128, 2048, 7, 7]   1,048,576    6,576,668,672\n",
      "145_layer4.1.BatchNorm2d_bn3                        [2048]     [128, 2048, 7, 7]       4,096       51,380,224\n",
      "146_layer4.1.ReLU_relu                                   -     [128, 2048, 7, 7]           0                0\n",
      "147_layer4.2.Conv2d_conv1                [2048, 512, 1, 1]      [128, 512, 7, 7]   1,048,576    6,576,668,672\n",
      "148_layer4.2.BatchNorm2d_bn1                         [512]      [128, 512, 7, 7]       1,024       12,845,056\n",
      "149_layer4.2.ReLU_relu                                   -      [128, 512, 7, 7]           0                0\n",
      "150_layer4.2.Conv2d_conv2                 [512, 512, 3, 3]      [128, 512, 7, 7]   2,359,296   14,797,504,512\n",
      "151_layer4.2.BatchNorm2d_bn2                         [512]      [128, 512, 7, 7]       1,024       12,845,056\n",
      "152_layer4.2.ReLU_relu                                   -      [128, 512, 7, 7]           0                0\n",
      "153_layer4.2.Conv2d_conv3                [512, 2048, 1, 1]     [128, 2048, 7, 7]   1,048,576    6,576,668,672\n",
      "154_layer4.2.BatchNorm2d_bn3                        [2048]     [128, 2048, 7, 7]       4,096       51,380,224\n",
      "155_layer4.2.ReLU_relu                                   -     [128, 2048, 7, 7]           0                0\n",
      "156_avgpool                                              -     [128, 2048, 1, 1]           0       13,107,200\n",
      "157_fc                                           [2048, 6]              [128, 6]      12,294        3,144,960\n",
      "=============================================================================================================\n",
      "Total params: 23,520,326\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,508,032\n",
      "Total FLOPs: 528,860,052,736 / 528.86 GFLOPs\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 73.50\n",
      "Forward/backward pass size (MB): 31288.51\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 31451.73\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "tu.get_model_summary(model, torch.randn(config['batch_size'], 3, 224, 224, device=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb209bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] Train loss: 0.2064, valid loss = 0.2359 Train acc 0.9272 Valid acc 0.9143\n",
      "[Epoch 01] Train loss: 0.2078, valid loss = 0.2465 Train acc 0.9266 Valid acc 0.9115\n",
      "[Epoch 02] Train loss: 0.2066, valid loss = 0.2505 Train acc 0.9269 Valid acc 0.9095\n",
      "[Epoch 03] Train loss: 0.2028, valid loss = 0.2318 Train acc 0.9272 Valid acc 0.9204\n",
      "[Epoch 04] Train loss: 0.2011, valid loss = 0.2320 Train acc 0.9255 Valid acc 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Acc history')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_epoch_acc = []\n",
    "train_epoch_losses = []\n",
    "valid_epoch_losses = []\n",
    "valid_epoch_acc = []\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc = (preds == labels).sum().item() / labels.size(0)\n",
    "        batch_acc.append(acc)\n",
    "        \n",
    "    train_epoch_acc.append(np.mean(batch_acc))\n",
    "    train_epoch_losses.append(np.mean(batch_loss))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc = (preds == labels).sum().item() / labels.size(0)\n",
    "            batch_acc.append(acc)\n",
    "            \n",
    "    valid_epoch_losses.append(np.mean(batch_loss))\n",
    "    valid_epoch_acc.append(np.mean(batch_acc))\n",
    "    print(f'[Epoch {epoch:02d}] Train loss: {train_epoch_losses[-1]:.4f}, valid loss = {valid_epoch_losses[-1]:.4f} Train acc {train_epoch_acc[-1]:.4f} Valid acc {valid_epoch_acc[-1]:.4f}')\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "ax[0].plot(train_epoch_losses)\n",
    "ax[0].plot(valid_epoch_losses)\n",
    "ax[0].set_ylim((0, np.max(train_epoch_losses.extend(valid_epoch_losses))))\n",
    "ax[0].set_title('Valid loss history')\n",
    "\n",
    "ax[1].plot(train_epoch_acc)\n",
    "ax[1].plot(valid_epoch_acc)\n",
    "ax[1].set_ylim(0, 1.1)\n",
    "ax[1].set_title('Acc history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5014c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102feb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
